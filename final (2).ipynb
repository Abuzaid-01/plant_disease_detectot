{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7379779,"sourceType":"datasetVersion","datasetId":4288635}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:01:37.320674Z","iopub.execute_input":"2025-05-02T10:01:37.320924Z","iopub.status.idle":"2025-05-02T10:01:38.987576Z","shell.execute_reply.started":"2025-05-02T10:01:37.320904Z","shell.execute_reply":"2025-05-02T10:01:38.986796Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ai-vs-human-text/AI_Human.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import  get_linear_schedule_with_warmup\nfrom torch.optim import AdamW\n\nfrom tqdm.auto import tqdm\nimport gc\nimport os\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:01:43.163687Z","iopub.execute_input":"2025-05-02T10:01:43.164266Z","iopub.status.idle":"2025-05-02T10:01:50.512059Z","shell.execute_reply.started":"2025-05-02T10:01:43.164241Z","shell.execute_reply":"2025-05-02T10:01:50.511466Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set seed for reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\n\n# Check GPU availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# For multiple GPUs\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:01:54.423152Z","iopub.execute_input":"2025-05-02T10:01:54.423612Z","iopub.status.idle":"2025-05-02T10:01:54.536627Z","shell.execute_reply.started":"2025-05-02T10:01:54.423587Z","shell.execute_reply":"2025-05-02T10:01:54.535788Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nUsing 2 GPUs!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Load data\ndf = pd.read_csv('/kaggle/input/ai-vs-human-text/AI_Human.csv')\n\n# Display basic information\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nFirst few rows:\")\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:01:56.440835Z","iopub.execute_input":"2025-05-02T10:01:56.441554Z","iopub.status.idle":"2025-05-02T10:02:25.274850Z","shell.execute_reply.started":"2025-05-02T10:01:56.441520Z","shell.execute_reply":"2025-05-02T10:02:25.274230Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (487235, 2)\n\nFirst few rows:\n                                                text  generated\n0  Cars. Cars have been around since they became ...        0.0\n1  Transportation is a large necessity in most co...        0.0\n2  \"America's love affair with it's vehicles seem...        0.0\n3  How often do you ride in a car? Do you drive a...        0.0\n4  Cars are a wonderful thing. They are perhaps o...        0.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\n# Check for missing values\nprint(\"\\nMissing values:\")\nprint(df.isnull().sum())\n\n# Check class distribution\nprint(\"\\nClass distribution:\")\nprint(df['generated'].value_counts())\n\n# Sample distribution visualization\nplt.figure(figsize=(8, 5))\nsns.countplot(x='generated', data=df)\nplt.title('Distribution of Human vs AI Generated Text')\nplt.xlabel('AI Generated (1) vs Human Text (0)')\nplt.ylabel('Count')\nplt.savefig('class_distribution.png')\nplt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:02:31.271285Z","iopub.execute_input":"2025-05-02T10:02:31.271789Z","iopub.status.idle":"2025-05-02T10:02:31.551953Z","shell.execute_reply.started":"2025-05-02T10:02:31.271764Z","shell.execute_reply":"2025-05-02T10:02:31.551122Z"}},"outputs":[{"name":"stdout","text":"\nMissing values:\ntext         0\ngenerated    0\ndtype: int64\n\nClass distribution:\ngenerated\n0.0    305797\n1.0    181438\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Prepare data for training\n# Convert text to list and labels to numpy array\ntexts = df['text'].tolist()\nlabels = df['generated'].values\n\n# Split data into training, validation and test sets (70%, 15%, 15%)\ntrain_texts, temp_texts, train_labels, temp_labels = train_test_split(\n    texts, labels, test_size=0.3, random_state=seed, stratify=labels\n)\nval_texts, test_texts, val_labels, test_labels = train_test_split(\n    temp_texts, temp_labels, test_size=0.5, random_state=seed, stratify=temp_labels\n)\n\nprint(f\"\\nTrain set: {len(train_texts)} samples\")\nprint(f\"Validation set: {len(val_texts)} samples\")\nprint(f\"Test set: {len(test_texts)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:02:33.501069Z","iopub.execute_input":"2025-05-02T10:02:33.501630Z","iopub.status.idle":"2025-05-02T10:02:33.884600Z","shell.execute_reply.started":"2025-05-02T10:02:33.501604Z","shell.execute_reply":"2025-05-02T10:02:33.883741Z"}},"outputs":[{"name":"stdout","text":"\nTrain set: 341064 samples\nValidation set: 73085 samples\nTest set: 73086 samples\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Define model name\nmodel_name = \"roberta-base\"  # You can try \"distilbert-base-uncased\" for faster training\n\n# Initialize tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmax_length = 256  # You can adjust this based on your texts\n\nprint(f\"\\nUsing {model_name} with max sequence length of {max_length}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:02:35.838385Z","iopub.execute_input":"2025-05-02T10:02:35.838661Z","iopub.status.idle":"2025-05-02T10:02:41.399695Z","shell.execute_reply.started":"2025-05-02T10:02:35.838637Z","shell.execute_reply":"2025-05-02T10:02:41.398907Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb4c09596d734e60ac52579c19c663fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c323362c4135485986897cb125a898ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85f0d515f0f749e7b08c96ff70c817f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01d9be3e9b6542e1b2e03169eb2bfca7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efd8203af957463bb95f3ed7a050bbf8"}},"metadata":{}},{"name":"stdout","text":"\nUsing roberta-base with max sequence length of 256\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Create a PyTorch Dataset\nclass TextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        \n        encoding = self.tokenizer(\n            text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:02:47.707252Z","iopub.execute_input":"2025-05-02T10:02:47.707546Z","iopub.status.idle":"2025-05-02T10:02:47.712993Z","shell.execute_reply.started":"2025-05-02T10:02:47.707526Z","shell.execute_reply":"2025-05-02T10:02:47.712028Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Create DataLoaders\ndef create_dataloaders(train_texts, val_texts, test_texts, train_labels, val_labels, test_labels, \n                     tokenizer, max_length, batch_size):\n    train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n    val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n    test_dataset = TextClassificationDataset(test_texts, test_labels, tokenizer, max_length)\n    \n    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=2)\n    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, num_workers=2)\n    \n    return train_dataloader, val_dataloader, test_dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:02:51.384266Z","iopub.execute_input":"2025-05-02T10:02:51.384974Z","iopub.status.idle":"2025-05-02T10:02:51.389317Z","shell.execute_reply.started":"2025-05-02T10:02:51.384951Z","shell.execute_reply":"2025-05-02T10:02:51.388648Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\n# Training function for one epoch\ndef train_epoch(model, dataloader, optimizer, scheduler, device):\n    model.train()\n    total_loss = 0\n    predictions = []\n    actual_labels = []\n    \n    progress_bar = tqdm(dataloader, desc=\"Training\")\n    \n    for batch in progress_bar:\n        optimizer.zero_grad()\n        \n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        \n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        \n        loss = outputs.loss\n        total_loss += loss.item()\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n        \n        # Get predictions\n        preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n        predictions.extend(preds)\n        actual_labels.extend(labels.cpu().numpy())\n        \n        progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = accuracy_score(actual_labels, predictions)\n    \n    return avg_loss, accuracy, predictions, actual_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:02:54.034929Z","iopub.execute_input":"2025-05-02T10:02:54.035750Z","iopub.status.idle":"2025-05-02T10:02:54.041479Z","shell.execute_reply.started":"2025-05-02T10:02:54.035720Z","shell.execute_reply":"2025-05-02T10:02:54.040766Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Evaluation function\ndef evaluate(model, dataloader, device):\n    model.eval()\n    total_loss = 0\n    predictions = []\n    actual_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n            \n            loss = outputs.loss\n            total_loss += loss.item()\n            \n            # Get predictions\n            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n            predictions.extend(preds)\n            actual_labels.extend(labels.cpu().numpy())\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = accuracy_score(actual_labels, predictions)\n    \n    return avg_loss, accuracy, predictions, actual_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:02:57.418749Z","iopub.execute_input":"2025-05-02T10:02:57.419419Z","iopub.status.idle":"2025-05-02T10:02:57.424815Z","shell.execute_reply.started":"2025-05-02T10:02:57.419393Z","shell.execute_reply":"2025-05-02T10:02:57.424100Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Create dataloaders\nbatch_size =64  # Adjust based on GPU memory\ntrain_dataloader, val_dataloader, test_dataloader = create_dataloaders(\n    train_texts, val_texts, test_texts, \n    train_labels, val_labels, test_labels,\n    tokenizer, max_length, batch_size\n)\n\n# Initialize model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name, \n    num_labels=2,\n    problem_type=\"single_label_classification\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:03:00.353442Z","iopub.execute_input":"2025-05-02T10:03:00.354072Z","iopub.status.idle":"2025-05-02T10:03:17.871953Z","shell.execute_reply.started":"2025-05-02T10:03:00.354042Z","shell.execute_reply":"2025-05-02T10:03:17.871230Z"}},"outputs":[{"name":"stderr","text":"2025-05-02 10:03:06.015383: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746180186.175151      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746180186.217256      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nXet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d063e84b769e43e8882dea7da12a3017"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"\n# Move model to GPU and use DataParallel if multiple GPUs are available\nif torch.cuda.device_count() > 1:\n    model = torch.nn.DataParallel(model)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:03:23.125814Z","iopub.execute_input":"2025-05-02T10:03:23.126554Z","iopub.status.idle":"2025-05-02T10:03:23.461534Z","shell.execute_reply.started":"2025-05-02T10:03:23.126528Z","shell.execute_reply":"2025-05-02T10:03:23.460987Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Set up optimizer and learning rate scheduler\nepochs = 2  # You can increase this for better accuracy\nlearning_rate = 2e-5\nwarmup_steps = int(0.1 * len(train_dataloader) * epochs)  # 10% of total steps\ntotal_steps = len(train_dataloader) * epochs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:03:27.567668Z","iopub.execute_input":"2025-05-02T10:03:27.568325Z","iopub.status.idle":"2025-05-02T10:03:27.572362Z","shell.execute_reply.started":"2025-05-02T10:03:27.568298Z","shell.execute_reply":"2025-05-02T10:03:27.571467Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Use AdamW optimizer\noptimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_steps\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:03:29.374833Z","iopub.execute_input":"2025-05-02T10:03:29.375128Z","iopub.status.idle":"2025-05-02T10:03:29.605850Z","shell.execute_reply.started":"2025-05-02T10:03:29.375106Z","shell.execute_reply":"2025-05-02T10:03:29.605113Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Training loop\nbest_val_accuracy = 0\ntraining_stats = []\n\nfor epoch in range(epochs):\n    print(f\"\\n{'='*20} Epoch {epoch+1}/{epochs} {'='*20}\")\n    \n    # Manual training loop instead of using train_epoch function\n    model.train()\n    total_train_loss = 0\n    train_preds = []\n    train_true_labels = []\n    \n    for batch in tqdm(train_dataloader, desc=\"Training\"):\n        optimizer.zero_grad()\n        \n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        \n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        \n        # Fix for multi-GPU setup: if loss is a tensor with multiple elements, use mean\n        loss = outputs.loss\n        if loss.dim() > 0:\n            loss = loss.mean()\n        \n        total_train_loss += loss.item()\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n        \n        # Get predictions\n        logits = outputs.logits\n        if logits.dim() > 2:  # Handle multi-GPU case\n            logits = logits.view(-1, logits.size(-1))\n        \n        preds = torch.argmax(logits, dim=1).cpu().numpy()\n        train_preds.extend(preds)\n        train_true_labels.extend(labels.cpu().numpy())\n    \n    train_loss = total_train_loss / len(train_dataloader)\n    train_accuracy = accuracy_score(train_true_labels, train_preds)\n    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n    \n    # Manual validation loop instead of using evaluate function\n    print(\"\\nValidating...\")\n    model.eval()\n    total_val_loss = 0\n    val_preds = []\n    val_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(val_dataloader, desc=\"Validating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            \n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n            \n            # Fix for multi-GPU setup: if loss is a tensor with multiple elements, use mean\n            loss = outputs.loss\n            if loss.dim() > 0:\n                loss = loss.mean()\n                \n            total_val_loss += loss.item()\n            \n            # Get predictions\n            logits = outputs.logits\n            if logits.dim() > 2:  # Handle multi-GPU case\n                logits = logits.view(-1, logits.size(-1))\n                \n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            val_preds.extend(preds)\n            val_labels.extend(labels.cpu().numpy())\n    \n    val_loss = total_val_loss / len(val_dataloader)\n    val_accuracy = accuracy_score(val_labels, val_preds)\n    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n    \n    # Save stats\n    training_stats.append({\n        'epoch': epoch + 1,\n        'train_loss': train_loss,\n        'train_accuracy': train_accuracy,\n        'val_loss': val_loss,\n        'val_accuracy': val_accuracy\n    })\n    \n    # Save best model\n    if val_accuracy > best_val_accuracy:\n        best_val_accuracy = val_accuracy\n        \n        # Save model\n        output_dir = './best_model'\n        os.makedirs(output_dir, exist_ok=True)\n        \n        if isinstance(model, torch.nn.DataParallel):\n            model_to_save = model.module\n        else:\n            model_to_save = model\n            \n        model_to_save.save_pretrained(output_dir)\n        tokenizer.save_pretrained(output_dir)\n        \n        print(f\"Saved new best model with validation accuracy: {val_accuracy:.4f}\")\n    \n    # Print classification report for validation set\n    print(\"\\nValidation Classification Report:\")\n    print(classification_report(val_labels, val_preds))\n    \n    # Clear memory\n    gc.collect()\n    torch.cuda.empty_cache()\n\n# Convert training stats to DataFrame for easy visualization\nstats_df = pd.DataFrame(training_stats)\nprint(\"\\nTraining Statistics:\")\nprint(stats_df)\n\n# Plot training and validation loss\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(stats_df['train_loss'], label='Train')\nplt.plot(stats_df['val_loss'], label='Validation')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\n\n# Plot training and validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(stats_df['train_accuracy'], label='Train')\nplt.plot(stats_df['val_accuracy'], label='Validation')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\nplt.tight_layout()\nplt.savefig('training_curves.png')\nplt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T10:03:37.531447Z","iopub.execute_input":"2025-05-02T10:03:37.531781Z","iopub.status.idle":"2025-05-02T15:29:21.920156Z","shell.execute_reply.started":"2025-05-02T10:03:37.531760Z","shell.execute_reply":"2025-05-02T15:29:21.919538Z"}},"outputs":[{"name":"stdout","text":"\n==================== Epoch 1/2 ====================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/5330 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c59820793cc4e53b3b6e2433a2050af"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0313, Train Accuracy: 0.9862\n\nValidating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/1142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d49da38c34974123b13e332e96105d9c"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.0118, Validation Accuracy: 0.9973\nSaved new best model with validation accuracy: 0.9973\n\nValidation Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     45869\n           1       0.99      1.00      1.00     27216\n\n    accuracy                           1.00     73085\n   macro avg       1.00      1.00      1.00     73085\nweighted avg       1.00      1.00      1.00     73085\n\n\n==================== Epoch 2/2 ====================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/5330 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6229429b67ab4cc68822e16e8cf4e484"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.0008, Train Accuracy: 0.9998\n\nValidating...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validating:   0%|          | 0/1142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"479ddfd501ea4185a2bbe9d0c46b1a6c"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 0.0071, Validation Accuracy: 0.9989\nSaved new best model with validation accuracy: 0.9989\n\nValidation Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     45869\n           1       1.00      1.00      1.00     27216\n\n    accuracy                           1.00     73085\n   macro avg       1.00      1.00      1.00     73085\nweighted avg       1.00      1.00      1.00     73085\n\n\nTraining Statistics:\n   epoch  train_loss  train_accuracy  val_loss  val_accuracy\n0      1    0.031335        0.986217  0.011787      0.997318\n1      2    0.000758        0.999833  0.007129      0.998878\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# Load the best model for evaluation\nbest_model = AutoModelForSequenceClassification.from_pretrained('./best_model')\nbest_model = best_model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:30:03.081411Z","iopub.execute_input":"2025-05-02T15:30:03.082101Z","iopub.status.idle":"2025-05-02T15:30:03.348674Z","shell.execute_reply.started":"2025-05-02T15:30:03.082072Z","shell.execute_reply":"2025-05-02T15:30:03.347906Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Evaluate on test set\nprint(\"\\nEvaluating on test set...\")\ntest_loss, test_accuracy, test_preds, test_labels = evaluate(best_model, test_dataloader, device)\nprint(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:30:14.920073Z","iopub.execute_input":"2025-05-02T15:30:14.920374Z","iopub.status.idle":"2025-05-02T15:48:41.314718Z","shell.execute_reply.started":"2025-05-02T15:30:14.920353Z","shell.execute_reply":"2025-05-02T15:48:41.313401Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating on test set...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/1142 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eec90ebc35cb495d9446ac8d47fba8c9"}},"metadata":{}},{"name":"stdout","text":"Test Loss: 0.0087, Test Accuracy: 0.9985\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Print classification report for test set\nprint(\"\\nTest Classification Report:\")\nprint(classification_report(test_labels, test_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:48:50.701790Z","iopub.execute_input":"2025-05-02T15:48:50.702153Z","iopub.status.idle":"2025-05-02T15:48:50.917699Z","shell.execute_reply.started":"2025-05-02T15:48:50.702115Z","shell.execute_reply":"2025-05-02T15:48:50.917103Z"}},"outputs":[{"name":"stdout","text":"\nTest Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00     45870\n           1       1.00      1.00      1.00     27216\n\n    accuracy                           1.00     73086\n   macro avg       1.00      1.00      1.00     73086\nweighted avg       1.00      1.00      1.00     73086\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Plot confusion matrix\ncm = confusion_matrix(test_labels, test_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.savefig('confusion_matrix.png')\nplt.show()\nplt.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:49:03.334907Z","iopub.execute_input":"2025-05-02T15:49:03.335156Z","iopub.status.idle":"2025-05-02T15:49:03.589054Z","shell.execute_reply.started":"2025-05-02T15:49:03.335139Z","shell.execute_reply":"2025-05-02T15:49:03.588329Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAApoAAAIjCAYAAACjybtCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCtElEQVR4nO3de1hVVf7H8c8B5YAoICqgedfyMpoXNKTyViQZmqaWVlN4m9JBUzFv1ZjahUYzL3mrrHCaLMvSSlMzSM2kNJS8jDreGjIFQRMUFRTO7w8fzs8TWKAsQff7Nc95Htl77bXXPk32fT5r7YXN4XA4BAAAAJQwt9IeAAAAAG5MFJoAAAAwgkITAAAARlBoAgAAwAgKTQAAABhBoQkAAAAjKDQBAABgBIUmAAAAjKDQBAAAgBEUmgD+0L59+9SlSxf5+vrKZrNp+fLlJdr/zz//LJvNptjY2BLt93rWqVMnderUqbSHAQBXjUITuA4cOHBATz75pOrXry9PT0/5+Pjojjvu0KxZs3T27Fmj946MjNSOHTv00ksv6b333lObNm2M3u9a6t+/v2w2m3x8fAr9Hvft2yebzSabzaZXX3212P0fOXJEkyZNUlJSUgmMFgCuP+VKewAA/tjKlSv14IMPym636/HHH1ezZs2Uk5OjjRs3asyYMdq1a5fefPNNI/c+e/asEhIS9Oyzz2rYsGFG7lGnTh2dPXtW5cuXN9L/nylXrpzOnDmjL774Qg899JDLuffff1+enp46d+7cFfV95MgRTZ48WXXr1lXLli2LfN1XX311RfcDgLKGQhMoww4dOqR+/fqpTp06io+PV/Xq1Z3noqKitH//fq1cudLY/dPS0iRJfn5+xu5hs9nk6elprP8/Y7fbdccdd+iDDz4oUGguXrxYERER+uSTT67JWM6cOaMKFSrIw8PjmtwPAExj6hwow6ZOnarTp0/r7bffdiky8zVs2FAjRoxw/nzhwgW98MILatCggex2u+rWratnnnlG2dnZLtfVrVtX3bp108aNG3XbbbfJ09NT9evX17/+9S9nm0mTJqlOnTqSpDFjxshms6lu3bqSLk455//5UpMmTZLNZnM5tnbtWt15553y8/NTxYoV1ahRIz3zzDPO85dboxkfH6/27dvL29tbfn5+6tGjh3bv3l3o/fbv36/+/fvLz89Pvr6+GjBggM6cOXP5L/Z3HnnkEa1atUonT550HtuyZYv27dunRx55pED7EydO6Omnn1bz5s1VsWJF+fj4qGvXrvrpp5+cbdatW6e2bdtKkgYMGOCcgs9/zk6dOqlZs2ZKTExUhw4dVKFCBef38vs1mpGRkfL09Czw/OHh4apcubKOHDlS5GcFgGuJQhMow7744gvVr19ft99+e5HaDx48WBMnTlTr1q01Y8YMdezYUTExMerXr1+Btvv371efPn10zz33aPr06apcubL69++vXbt2SZJ69eqlGTNmSJIefvhhvffee5o5c2axxr9r1y5169ZN2dnZmjJliqZPn677779f33333R9e9/XXXys8PFzHjh3TpEmTFB0drU2bNumOO+7Qzz//XKD9Qw89pFOnTikmJkYPPfSQYmNjNXny5CKPs1evXrLZbPr000+dxxYvXqzGjRurdevWBdofPHhQy5cvV7du3fTaa69pzJgx2rFjhzp27Ogs+po0aaIpU6ZIkp544gm99957eu+999ShQwdnP8ePH1fXrl3VsmVLzZw5U507dy50fLNmzVK1atUUGRmp3NxcSdIbb7yhr776Sq+//rpq1KhR5GcFgGvKAaBMysjIcEhy9OjRo0jtk5KSHJIcgwcPdjn+9NNPOyQ54uPjncfq1KnjkOTYsGGD89ixY8ccdrvdMXr0aOexQ4cOOSQ5pk2b5tJnZGSko06dOgXG8Pzzzzsu/WtlxowZDkmOtLS0y447/x7vvvuu81jLli0dAQEBjuPHjzuP/fTTTw43NzfH448/XuB+AwcOdOnzgQcecFSpUuWy97z0Oby9vR0Oh8PRp08fx9133+1wOByO3NxcR1BQkGPy5MmFfgfnzp1z5ObmFngOu93umDJlivPYli1bCjxbvo4dOzokORYsWFDouY4dO7ocW7NmjUOS48UXX3QcPHjQUbFiRUfPnj3/9BkBoDSRaAJlVGZmpiSpUqVKRWr/5ZdfSpKio6Ndjo8ePVqSCqzlbNq0qdq3b+/8uVq1amrUqJEOHjx4xWP+vfy1nZ999pny8vKKdM3Ro0eVlJSk/v37y9/f33n81ltv1T333ON8zksNGTLE5ef27dvr+PHjzu+wKB555BGtW7dOKSkpio+PV0pKSqHT5tLFdZ1ubhf/+szNzdXx48edywK2bt1a5Hva7XYNGDCgSG27dOmiJ598UlOmTFGvXr3k6empN954o8j3AoDSQKEJlFE+Pj6SpFOnThWp/f/+9z+5ubmpYcOGLseDgoLk5+en//3vfy7Ha9euXaCPypUr67fffrvCERfUt29f3XHHHRo8eLACAwPVr18/ffTRR39YdOaPs1GjRgXONWnSROnp6crKynI5/vtnqVy5siQV61nuu+8+VapUSUuWLNH777+vtm3bFvgu8+Xl5WnGjBm6+eabZbfbVbVqVVWrVk3bt29XRkZGke950003FevFn1dffVX+/v5KSkrS7NmzFRAQUORrAaA0UGgCZZSPj49q1KihnTt3Fuu637+Mcznu7u6FHnc4HFd8j/z1g/m8vLy0YcMGff3113rssce0fft29e3bV/fcc0+Btlfjap4ln91uV69evbRo0SItW7bssmmmJL388suKjo5Whw4d9O9//1tr1qzR2rVr9Ze//KXIya108fspjm3btunYsWOSpB07dhTrWgAoDRSaQBnWrVs3HThwQAkJCX/atk6dOsrLy9O+fftcjqempurkyZPON8hLQuXKlV3e0M73+9RUktzc3HT33Xfrtdde03/+8x+99NJLio+P1zfffFNo3/nj3Lt3b4Fze/bsUdWqVeXt7X11D3AZjzzyiLZt26ZTp04V+gJVvqVLl6pz5856++231a9fP3Xp0kVhYWEFvpOiFv1FkZWVpQEDBqhp06Z64oknNHXqVG3ZsqXE+gcAEyg0gTJs7Nix8vb21uDBg5Wamlrg/IEDBzRr1ixJF6d+JRV4M/y1116TJEVERJTYuBo0aKCMjAxt377deezo0aNatmyZS7sTJ04UuDZ/4/Lfb7mUr3r16mrZsqUWLVrkUrjt3LlTX331lfM5TejcubNeeOEFzZkzR0FBQZdt5+7uXiAt/fjjj/Xrr7+6HMsviAsryotr3LhxSk5O1qJFi/Taa6+pbt26ioyMvOz3CABlARu2A2VYgwYNtHjxYvXt21dNmjRx+c1AmzZt0scff6z+/ftLklq0aKHIyEi9+eabOnnypDp27KjNmzdr0aJF6tmz52W3zrkS/fr107hx4/TAAw/oqaee0pkzZzR//nzdcsstLi/DTJkyRRs2bFBERITq1KmjY8eOad68eapZs6buvPPOy/Y/bdo0de3aVaGhoRo0aJDOnj2r119/Xb6+vpo0aVKJPcfvubm56bnnnvvTdt26ddOUKVM0YMAA3X777dqxY4fef/991a9f36VdgwYN5OfnpwULFqhSpUry9vZWSEiI6tWrV6xxxcfHa968eXr++eed2y29++676tSpk/7xj39o6tSpxeoPAK4VEk2gjLv//vu1fft29enTR5999pmioqI0fvx4/fzzz5o+fbpmz57tbLtw4UJNnjxZW7Zs0ciRIxUfH68JEyboww8/LNExValSRcuWLVOFChU0duxYLVq0SDExMerevXuBsdeuXVvvvPOOoqKiNHfuXHXo0EHx8fHy9fW9bP9hYWFavXq1qlSpookTJ+rVV19Vu3bt9N133xW7SDPhmWee0ejRo7VmzRqNGDFCW7du1cqVK1WrVi2XduXLl9eiRYvk7u6uIUOG6OGHH9b69euLda9Tp05p4MCBatWqlZ599lnn8fbt22vEiBGaPn26vv/++xJ5LgAoaTZHcVbLAwAAAEVEogkAAAAjKDQBAABgBIUmAAAAjKDQBAAAgBEUmgAAADCCQhMAAABGUGgCAADAiBvyNwN5tRpW2kMAYMhvW+aU9hAAGOJZilWJydrh7Dbr/r1FogkAAAAjbshEEwAAoFhsZG8mUGgCAADYbKU9ghsS5TsAAACMINEEAABg6twIvlUAAAAYQaIJAADAGk0jSDQBAABgBIkmAAAAazSN4FsFAACAESSaAAAArNE0gkITAACAqXMj+FYBAABgBIkmAAAAU+dGkGgCAADACBJNAAAA1mgawbcKAAAAI0g0AQAAWKNpBIkmAAAAjCDRBAAAYI2mERSaAAAATJ0bQfkOAAAAI0g0AQAAmDo3gm8VAAAARpBoAgAAkGgawbcKAAAAI0g0AQAA3Hjr3AQSTQAAABhBogkAAMAaTSMoNAEAANiw3QjKdwAAABhBogkAAMDUuRF8qwAAADCCRBMAAIA1mkaQaAIAAMAIEk0AAADWaBrBtwoAAAAjSDQBAABYo2kEhSYAAABT50bwrQIAAMAIEk0AAACmzo0g0QQAAIARJJoAAACs0TSCbxUAAABGkGgCAACwRtMIEk0AAAAYQaIJAADAGk0jKDQBAAAoNI3gWwUAAIARJJoAAAC8DGQEiSYAAACMINEEAABgjaYRfKsAAAAwgkITAADAZjP3uQqvvPKKbDabRo4c6Tx27tw5RUVFqUqVKqpYsaJ69+6t1NRUl+uSk5MVERGhChUqKCAgQGPGjNGFCxdc2qxbt06tW7eW3W5Xw4YNFRsbW+D+c+fOVd26deXp6amQkBBt3ry5WOOn0AQAACiDtmzZojfeeEO33nqry/FRo0bpiy++0Mcff6z169fryJEj6tWrl/N8bm6uIiIilJOTo02bNmnRokWKjY3VxIkTnW0OHTqkiIgIde7cWUlJSRo5cqQGDx6sNWvWONssWbJE0dHRev7557V161a1aNFC4eHhOnbsWJGfweZwOBxX8R2USV6thpX2EAAY8tuWOaU9BACGeJbimyNeDyw01vfZZYOLfc3p06fVunVrzZs3Ty+++KJatmypmTNnKiMjQ9WqVdPixYvVp08fSdKePXvUpEkTJSQkqF27dlq1apW6deumI0eOKDAwUJK0YMECjRs3TmlpafLw8NC4ceO0cuVK7dy503nPfv366eTJk1q9erUkKSQkRG3bttWcORf/3s3Ly1OtWrU0fPhwjR8/vkjPQaIJAABgcOo8OztbmZmZLp/s7Ow/HE5UVJQiIiIUFhbmcjwxMVHnz593Od64cWPVrl1bCQkJkqSEhAQ1b97cWWRKUnh4uDIzM7Vr1y5nm9/3HR4e7uwjJydHiYmJLm3c3NwUFhbmbFMUFJoAAAAGxcTEyNfX1+UTExNz2fYffvihtm7dWmiblJQUeXh4yM/Pz+V4YGCgUlJSnG0uLTLzz+ef+6M2mZmZOnv2rNLT05Wbm1tom/w+ioLtjQAAgOXZDG7YPmHCBEVHR7scs9vthbb95ZdfNGLECK1du1aenp7GxnStkGgCAAAYZLfb5ePj4/K5XKGZmJioY8eOqXXr1ipXrpzKlSun9evXa/bs2SpXrpwCAwOVk5OjkydPulyXmpqqoKAgSVJQUFCBt9Dzf/6zNj4+PvLy8lLVqlXl7u5eaJv8PoqCQhMAAFiezWYz9imOu+++Wzt27FBSUpLz06ZNGz366KPOP5cvX15xcXHOa/bu3avk5GSFhoZKkkJDQ7Vjxw6Xt8PXrl0rHx8fNW3a1Nnm0j7y2+T34eHhoeDgYJc2eXl5iouLc7YpCqbOAQAAyohKlSqpWbNmLse8vb1VpUoV5/FBgwYpOjpa/v7+8vHx0fDhwxUaGqp27dpJkrp06aKmTZvqscce09SpU5WSkqLnnntOUVFRziR1yJAhmjNnjsaOHauBAwcqPj5eH330kVauXOm8b3R0tCIjI9WmTRvddtttmjlzprKysjRgwIAiPw+FJgAAgLklmiVuxowZcnNzU+/evZWdna3w8HDNmzfPed7d3V0rVqzQ0KFDFRoaKm9vb0VGRmrKlCnONvXq1dPKlSs1atQozZo1SzVr1tTChQsVHh7ubNO3b1+lpaVp4sSJSklJUcuWLbV69eoCLwj9EfbRBHBdYR9N4MZVmvtoej/4rrG+sz4uegJ4oyHRBAAAlmfyrXMro9AEAACWR6FpBm+dAwAAwAgSTQAAYHkkmmaQaAIAAMAIEk0AAGB5JJpmkGgCAADACBJNAAAAAk0jSDQBAABgBIkmAACwPNZomkGiCQAAACNINAEAgOWRaJpBoQkAACyPQtMMps4BAABgBIkmAACwPBJNM0g0AQAAYASJJgAAAIGmESSaAAAAMIJEEwAAWB5rNM0g0QQAAIARJJoAAMDySDTNoNAEAACWR6FpBlPnAAAAMIJEEwAAgEDTCBJNAAAAGEGiCQAALI81mmaQaAIAAMAIEk0AAGB5JJpmkGgCAADACBJNAABgeSSaZlBoAgAAy6PQNIOpcwAAABhBogkAAECgaQSJJgAAAIwg0QQAAJbHGk0zSDQBAABgBIkmAACwPBJNM0g0AQAAYASJJgAAsDwSTTMoNAEAAKgzjWDqHAAAAEaQaAIAAMtj6twMEk0AAAAYQaIJAAAsj0TTDBJNAAAAGEGiiVL19IB79MJTPTTn/W805tVPJElr3hqhDm1udmn31tKNeuqlDyVJf+0eoremPFZof7XvGq+0305LkjzKl9MzT3TVwxFtFVilklLSM/Xym6v0r8++lyT1uKuFxgwKV4NaVVW+nLv2J6dp1ntx+mDlFlOPC0BS4o9bFPvO29r9n51KS0vTjNlzddfdYc7zDodD8+bM1qdLP9apU5lq2aq1np04SXXq1JUkbdn8gwYPeLzQvt//8GM1a37rtXgM3GBINM2g0ESpCW5aW4N636Ht/z1c4Nzbn3ynF+avcP585tx555+XfrVVazf9x6X9m5Mfk6e9vLPIlKR/Tx2oQP9KGjL5fR1ITlP1ar5yu+QvkhMZZzR14Wrt/TlVOedzdV/7Znpz0l+VduK0vk7YXZKPCuASZ8+eUaNGjdSzV29FjxhW4Py7b7+lD95/Ty+8/Ipuuqmm5r4+S0OfGKRln38pu92uli1bKW7dRpdr5r4+Sz/8kKC/NGt+rR4DQBFQaKJUeHt56N2X++vvL3yg8YPvLXD+7LkcpR4/Vei157LP61z2/xeeVStXVKfbbtGQye87j91zexO1D26opt0m6bfMM5Kk5KMnXPr5NnGfy89zP1inR7uH6PZW9Sk0AYPubN9Rd7bvWOg5h8Oh99/7l/725FB1vutiyvlizFTd1eF2xcd9ra73Rai8h4eqVqvmvOb8+fP65ps4PfzIX0mlcMX4/44ZpbpGMz09XVOnTtUDDzyg0NBQhYaG6oEHHtC0adOUlpZWmkODYTMn9NXqb3fqmx/2Fnq+731t9Ev8K/rx42c0Zfj98vIsf9m+Hu12m86cy9Gyr5OcxyI6NtfW/yQrun+YDqx5UduXT1TMqAfkab98P51uu0W31A3QxsQDV/xcAK7Or4cPKz09TSHtbnceq1Spkprf2kLbf9pW6DXrv4lXxsmT6vlA72s1TNyIbAY/FlZqieaWLVsUHh6uChUqKCwsTLfccoskKTU1VbNnz9Yrr7yiNWvWqE2bNn/YT3Z2trKzs12OOfJyZXNzNzZ2XJ0Hw4PVsnEt3fnXqYWeX7LqRyUfPaGjaRlqfnMNvTiih26pE6B+Ty8stH1kz1AtWfWjS8pZ76aqur1lA53LvqC+0W+pSmVvzZrQV/6+3npy0r+d7XwqeurAmpdkL19OuXl5GhGzRPE/7CnZBwZQZOnpF0OGKlWruByvUqWK0tPTC71m2adLdfsddyowKMj4+AAUT6kVmsOHD9eDDz6oBQsWFIirHQ6HhgwZouHDhyshIeEP+4mJidHkyZNdjrkHtlX56reV+Jhx9WoG+mnamN7qNnSOsnMuFNrmnU+/c/551/4jOpqeqdVvPqV6Navq0GHX/9CE3FpPTepX16Dn/uVy3M3NJofDoQHPxirz9DlJ0rjpn2rxtEEaEbPEWZSeyspWSL8YVfSyq3NII/1zdC8dOny8wLQ6gLIpNSVFm77bqGnTZ5b2UHCdY+rcjFIrNH/66SfFxsYW+g/WZrNp1KhRatWq1Z/2M2HCBEVHR7scC2g/rsTGiZLVqkltBVbxUcLi//9nVK6cu+5s3UBD+naQb8hI5eU5XK7ZsuNnSVKDWtUKFJr9HwhV0p5ftG33Ly7HU9IzdeRYhrPIlKQ9h1Lk5uammwL9dCD5YmricDh08JeLfW7/769qVC9IYwZ2odAESknVqhfXXh5PP65q1QKcx48fP65GjRsXaL982Sfy9fNTx853XbMxAii6Uis0g4KCtHnzZjUu5C8OSdq8ebMCAwP/tB+73S673e5yjGnzsuubzXsV3Ocll2NvTv6r9h5K1fTYtQWKTElq0aimJCklPcPluLeXh3rf01oTX/+8wDUJSQfVK6yVvL08lHU2R5J0c50A5ebm6dfUk5cdn5vNJrsH78gBpeWmmjVVtWo1/fBDgho3aSJJOn36tHZs/0kP9n3Ypa3D4dBnyz9V9/t7qnz5y6+/BoqCRNOMUvsv6tNPP60nnnhCiYmJuvvuu51FZWpqquLi4vTWW2/p1VdfLa3hwZDTZ7L1nwNHXY5lnc3RiYws/efAUdWrWVV9u7bRmo27dPxklprfcpOmju6lbxP3aee+Iy7X9QkPVjl3t0L3vVyyaosm/O1evTn5r3phwZeq4uetl0c+oEWfJTinzZ8e2EVbdyXr4OE02T3K6d47/6JHIm7TUzEfmvsCAOhMVpaSk5OdP/96+LD27N4tX19fVa9RQ48+9rjeemO+6tSuo5tqXtzeqFpAgMtem5K0+Yfv9evhw+rVu8+1fgQARVRqhWZUVJSqVq2qGTNmaN68ecrNzZUkubu7Kzg4WLGxsXrooYdKa3goJefPX9BdIY007JHO8vby0OHU37Q8LkmvLFxToG3/nqH6LP4nZZw+W+Bc1tkcRQydo9fGPajv/j1WJzKy9MnarZo09//35vT29NCsZx7STQF+Opt9Xv/9OVUDn1ukpV9tNfqMgNXt2rXTZcP1V6fGSJLu7/GAXnj5FQ0Y9DedPXtWUyZN1KlTmWrVOljz3lhYYPZq2SdL1bJlK9Wr3+Cajh83JgJNM2wOh6PgXOU1dv78eefbhFWrVr3qKRCvVgU3AAZwY/hty5zSHgIAQzxLceVSw6dXGet7/6tdjfVd1pWJxWjly5dX9erVS3sYAADAolijaUaZKDQBAABKE3WmGaX6m4EAAABw4yLRBAAAlsfUuRkkmgAAADCCRBMAAFgegaYZJJoAAAAwgkQTAABYnpsbkaYJJJoAAAAwgkQTAABYHms0zaDQBAAAlsf2RmYwdQ4AAAAjSDQBAIDlEWiaQaIJAAAAI0g0AQCA5bFG0wwSTQAAABhBogkAACyPRNMMEk0AAAAYQaIJAAAsj0DTDApNAABgeUydm8HUOQAAAIwg0QQAAJZHoGkGiSYAAACMINEEAACWxxpNM0g0AQAAYASJJgAAsDwCTTNINAEAAGAEiSYAALA81miaQaIJAAAAI0g0AQCA5RFomkGhCQAALI+pczOYOgcAAIARJJoAAMDyCDTNINEEAACAERSaAADA8mw2m7FPccyfP1+33nqrfHx85OPjo9DQUK1atcp5/ty5c4qKilKVKlVUsWJF9e7dW6mpqS59JCcnKyIiQhUqVFBAQIDGjBmjCxcuuLRZt26dWrduLbvdroYNGyo2NrbAWObOnau6devK09NTISEh2rx5c7GeRaLQBAAAKDNq1qypV155RYmJifrxxx911113qUePHtq1a5ckadSoUfriiy/08ccfa/369Tpy5Ih69erlvD43N1cRERHKycnRpk2btGjRIsXGxmrixInONocOHVJERIQ6d+6spKQkjRw5UoMHD9aaNWucbZYsWaLo6Gg9//zz2rp1q1q0aKHw8HAdO3asWM9jczgcjqv8Tsocr1bDSnsIAAz5bcuc0h4CAEM8S/HNkdunbjDW96axHa7qen9/f02bNk19+vRRtWrVtHjxYvXp00eStGfPHjVp0kQJCQlq166dVq1apW7duunIkSMKDAyUJC1YsEDjxo1TWlqaPDw8NG7cOK1cuVI7d+503qNfv346efKkVq9eLUkKCQlR27ZtNWfOxb9z8/LyVKtWLQ0fPlzjx48v8thJNAEAAAzKzs5WZmamyyc7O/tPr8vNzdWHH36orKwshYaGKjExUefPn1dYWJizTePGjVW7dm0lJCRIkhISEtS8eXNnkSlJ4eHhyszMdKaiCQkJLn3kt8nvIycnR4mJiS5t3NzcFBYW5mxTVBSaAADA8kyu0YyJiZGvr6/LJyYm5rJj2bFjhypWrCi73a4hQ4Zo2bJlatq0qVJSUuTh4SE/Pz+X9oGBgUpJSZEkpaSkuBSZ+efzz/1Rm8zMTJ09e1bp6enKzc0ttE1+H0XF9kYAAMDyTG5vNGHCBEVHR7scs9vtl23fqFEjJSUlKSMjQ0uXLlVkZKTWr19vboAGUWgCAAAYZLfb/7Cw/D0PDw81bNhQkhQcHKwtW7Zo1qxZ6tu3r3JycnTy5EmXVDM1NVVBQUGSpKCgoAJvh+e/lX5pm9+/qZ6amiofHx95eXnJ3d1d7u7uhbbJ76OomDoHAACWV1a2NypMXl6esrOzFRwcrPLlyysuLs55bu/evUpOTlZoaKgkKTQ0VDt27HB5O3zt2rXy8fFR06ZNnW0u7SO/TX4fHh4eCg4OdmmTl5enuLg4Z5uiItEEAAAoIyZMmKCuXbuqdu3aOnXqlBYvXqx169ZpzZo18vX11aBBgxQdHS1/f3/5+Pho+PDhCg0NVbt27SRJXbp0UdOmTfXYY49p6tSpSklJ0XPPPaeoqChnqjpkyBDNmTNHY8eO1cCBAxUfH6+PPvpIK1eudI4jOjpakZGRatOmjW677TbNnDlTWVlZGjBgQLGeh0ITAABYXkkkjyXh2LFjevzxx3X06FH5+vrq1ltv1Zo1a3TPPfdIkmbMmCE3Nzf17t1b2dnZCg8P17x585zXu7u7a8WKFRo6dKhCQ0Pl7e2tyMhITZkyxdmmXr16WrlypUaNGqVZs2apZs2aWrhwocLDw51t+vbtq7S0NE2cOFEpKSlq2bKlVq9eXeAFoT/DPpoArivsowncuEpzH80Or31nrO8N0XcY67usI9EEAACWV0YCzRsOLwMBAADACBJNAABgeWVljeaNhkITAABYHnWmGUydAwAAwAgSTQAAYHlMnZtBogkAAAAjSDQBAIDlEWiaQaIJAAAAI0g0AQCA5bkRaRpBogkAAAAjSDQBAIDlEWiaQaEJAAAsj+2NzGDqHAAAAEaQaAIAAMtzI9A0gkQTAAAARpBoAgAAy2ONphkkmgAAADCCRBMAAFgegaYZJJoAAAAwgkQTAABYnk1EmiZQaAIAAMtjeyMzmDoHAACAESSaAADA8tjeyAwSTQAAABhBogkAACyPQNMMEk0AAAAYQaIJAAAsz41I0wgSTQAAABhBogkAACyPQNMMCk0AAGB5bG9kBlPnAAAAMIJEEwAAWB6BphkkmgAAADCCRBMAAFge2xuZQaIJAAAAI0g0AQCA5ZFnmkGiCQAAACNINAEAgOWxj6YZFJoAAMDy3KgzjWDqHAAAAEaQaAIAAMtj6twMEk0AAAAYQaIJAAAsj0DTDBJNAAAAGEGiCQAALI81mmYUqdD8/PPPi9zh/ffff8WDAQAAwI2jSIVmz549i9SZzWZTbm7u1YwHAADgmmMfTTOKVGjm5eWZHgcAAECpYercDF4GAgAAgBFX9DJQVlaW1q9fr+TkZOXk5Lice+qpp0pkYAAAANcKeaYZxS40t23bpvvuu09nzpxRVlaW/P39lZ6ergoVKiggIIBCEwAAAJKuYOp81KhR6t69u3777Td5eXnp+++/1//+9z8FBwfr1VdfNTFGAAAAo9xsNmMfKyt2oZmUlKTRo0fLzc1N7u7uys7OVq1atTR16lQ988wzJsYIAACA61CxC83y5cvLze3iZQEBAUpOTpYk+fr66pdffinZ0QEAAFwDNpu5j5UVe41mq1attGXLFt18883q2LGjJk6cqPT0dL333ntq1qyZiTECAADgOlTsRPPll19W9erVJUkvvfSSKleurKFDhyotLU1vvvlmiQ8QAADANJvNZuxjZcVONNu0aeP8c0BAgFavXl2iAwIAAMCN4Yr20QQAALiRWDx4NKbYhWa9evX+MAY+ePDgVQ0IAADgWrP6NkSmFLvQHDlypMvP58+f17Zt27R69WqNGTOmpMYFAACA61yxC80RI0YUenzu3Ln68ccfr3pAAAAA1xqBphnFfuv8crp27apPPvmkpLoDAADAda7EXgZaunSp/P39S6o7AACAa8bq2xCZckUbtl/6D8PhcCglJUVpaWmaN29eiQ4OAAAA169iF5o9evRwKTTd3NxUrVo1derUSY0bNy7RwV2p37bMKe0hADCkz9tbSnsIAAxZ8WTbUrt3ia0lhItiF5qTJk0yMAwAAADcaIpdwLu7u+vYsWMFjh8/flzu7u4lMigAAIBriV9BaUaxE02Hw1Ho8ezsbHl4eFz1gAAAAK41N2vXg8YUudCcPXu2pIsV/8KFC1WxYkXnudzcXG3YsKHMrNEEAABA6StyoTljxgxJFxPNBQsWuEyTe3h4qG7dulqwYEHJjxAAAMAwEk0zilxoHjp0SJLUuXNnffrpp6pcubKxQQEAAOD6V+w1mt98842JcQAAAJQaq7+0Y0qx3zrv3bu3/vnPfxY4PnXqVD344IMlMigAAABc/4pdaG7YsEH33XdfgeNdu3bVhg0bSmRQAAAA15KbzdzHyopdaJ4+fbrQbYzKly+vzMzMEhkUAAAArn/FLjSbN2+uJUuWFDj+4YcfqmnTpiUyKAAAgGvJZjP3sbJivwz0j3/8Q7169dKBAwd01113SZLi4uK0ePFiLV26tMQHCAAAYJqb1StCQ4pdaHbv3l3Lly/Xyy+/rKVLl8rLy0stWrRQfHy8/P39TYwRAAAA16FiF5qSFBERoYiICElSZmamPvjgAz399NNKTExUbm5uiQ4QAADAtGKvJUSRXPH3umHDBkVGRqpGjRqaPn267rrrLn3//fclOTYAAABcx4qVaKakpCg2NlZvv/22MjMz9dBDDyk7O1vLly/nRSAAAHDdYommGUVONLt3765GjRpp+/btmjlzpo4cOaLXX3/d5NgAAABwHStyorlq1So99dRTGjp0qG6++WaTYwIAALimeOvcjCInmhs3btSpU6cUHByskJAQzZkzR+np6SbHBgAAgOtYkQvNdu3a6a233tLRo0f15JNP6sMPP1SNGjWUl5entWvX6tSpUybHCQAAYAwbtptR7LfOvb29NXDgQG3cuFE7duzQ6NGj9corryggIED333+/iTECAAAYxe86N+Oqto1q1KiRpk6dqsOHD+uDDz4oqTEBAADgBnBFG7b/nru7u3r27KmePXuWRHcAAADXFC8DmcFG+AAAADCCQhMAAFheWXkZKCYmRm3btlWlSpUUEBCgnj17au/evS5tzp07p6ioKFWpUkUVK1ZU7969lZqa6tImOTlZERERqlChggICAjRmzBhduHDBpc26devUunVr2e12NWzYULGxsQXGM3fuXNWtW1eenp4KCQnR5s2bi/U8FJoAAABlxPr16xUVFaXvv/9ea9eu1fnz59WlSxdlZWU524waNUpffPGFPv74Y61fv15HjhxRr169nOdzc3MVERGhnJwcbdq0SYsWLVJsbKwmTpzobHPo0CFFRESoc+fOSkpK0siRIzV48GCtWbPG2WbJkiWKjo7W888/r61bt6pFixYKDw/XsWPHivw8NofD4bjK76TMOXfhz9sAuD71eXtLaQ8BgCErnmxbavd+KW6/sb6fvbvhFV+blpamgIAArV+/Xh06dFBGRoaqVaumxYsXq0+fPpKkPXv2qEmTJkpISFC7du20atUqdevWTUeOHFFgYKAkacGCBRo3bpzS0tLk4eGhcePGaeXKldq5c6fzXv369dPJkye1evVqSVJISIjatm2rOXPmSJLy8vJUq1YtDR8+XOPHjy/S+Ek0AQAADMrOzlZmZqbLJzs7u0jXZmRkSJL8/f0lSYmJiTp//rzCwsKcbRo3bqzatWsrISFBkpSQkKDmzZs7i0xJCg8PV2Zmpnbt2uVsc2kf+W3y+8jJyVFiYqJLGzc3N4WFhTnbFAWFJgAAsDybwf/FxMTI19fX5RMTE/OnY8rLy9PIkSN1xx13qFmzZpKklJQUeXh4yM/Pz6VtYGCgUlJSnG0uLTLzz+ef+6M2mZmZOnv2rNLT05Wbm1tom/w+iqJEtjcCAAC4npncWH3ChAmKjo52OWa32//0uqioKO3cuVMbN240NTTjKDQBAAAMstvtRSosLzVs2DCtWLFCGzZsUM2aNZ3Hg4KClJOTo5MnT7qkmqmpqQoKCnK2+f3b4flvpV/a5vdvqqempsrHx0deXl5yd3eXu7t7oW3y+ygKps4BAIDllZVfQelwODRs2DAtW7ZM8fHxqlevnsv54OBglS9fXnFxcc5je/fuVXJyskJDQyVJoaGh2rFjh8vb4WvXrpWPj4+aNm3qbHNpH/lt8vvw8PBQcHCwS5u8vDzFxcU52xQFiSYAAEAZERUVpcWLF+uzzz5TpUqVnOshfX195eXlJV9fXw0aNEjR0dHy9/eXj4+Phg8frtDQULVr106S1KVLFzVt2lSPPfaYpk6dqpSUFD333HOKiopyJqtDhgzRnDlzNHbsWA0cOFDx8fH66KOPtHLlSudYoqOjFRkZqTZt2ui2227TzJkzlZWVpQEDBhT5eSg0AQCA5dnKyK+gnD9/viSpU6dOLsffffdd9e/fX5I0Y8YMubm5qXfv3srOzlZ4eLjmzZvnbOvu7q4VK1Zo6NChCg0Nlbe3tyIjIzVlyhRnm3r16mnlypUaNWqUZs2apZo1a2rhwoUKDw93tunbt6/S0tI0ceJEpaSkqGXLllq9enWBF4T+CPtoAriusI8mcOMqzX00p607aKzvMZ3qG+u7rCPRBAAAlmfyrXMr42UgAAAAGEGiCQAALK+MLNG84VBoAgAAy3Oj0jSCqXMAAAAYQaIJAAAsj5eBzCDRBAAAgBEkmgAAwPJYomkGiSYAAACMINEEAACW5yYiTRNINAEAAGAEiSYAALA81miaQaEJAAAsj+2NzGDqHAAAAEaQaAIAAMvjV1CaQaIJAAAAI0g0AQCA5RFomkGiCQAAACNINAEAgOWxRtMMEk0AAAAYQaIJAAAsj0DTDApNAABgeUzxmsH3CgAAACNINAEAgOXZmDs3gkQTAAAARpBoAgAAyyPPNINEEwAAAEaQaAIAAMtjw3YzSDQBAABgBIkmAACwPPJMMyg0AQCA5TFzbgZT5wAAADCCRBMAAFgeG7abQaIJAAAAI0g0AQCA5ZG8mcH3CgAAACNINAEAgOWxRtMMEk0AAAAYQaIJAAAsjzzTDBJNAAAAGEGiCQAALI81mmZQaAIAAMtjitcMvlcAAAAYQaIJAAAsj6lzM0g0AQAAYASJJgAAsDzyTDNINAEAAGAEiSYAALA8lmiaQaIJAAAAI0g0AQCA5bmxStMICk0AAGB5TJ2bwdQ5AAAAjCDRBAAAlmdj6twIEk0AAAAYQaIJAAAsjzWaZpBoAgAAwAgSTQAAYHlsb2QGiSYAAACMINEEAACWxxpNMyg0AQCA5VFomsHUOQAAAIwg0QQAAJbHhu1mkGgCAADACBJNAABgeW4EmkaQaAIAAMAIEk0AAGB5rNE0g0QTAAAARpBoAgAAy2MfTTMoNAEAgOUxdW4GU+cAAAAwgkQTAABYHtsbmUGiCQAAACNINAEAgOWxRtMMEk0AAAAYQaKJ61Lij1sU+87b2v2fnUpLS9OM2XN1191hpT0swNIebFldofUqq6afp3Jy87Q75bRifzisXzPOSZICKnronUdbFHptzNr9+u7gb6rn76U+raqraVAl+XiW07FT2Vr1nzR9vjPV2bZyhfIa1K6Wbq7mreq+dn2xM1VvbfrFpb+7b6miUZ3ruxzLuZCnXm8nlvBT40bB9kZmUGjiunT27Bk1atRIPXv1VvSIYaU9HACSmtWopJW7UrUvLUvuNpsev62mXoi4RUM/2qnsC3lKz8rRX/+1zeWae5sEqFeLICUmZ0iSGlbzVsbZC5oef1Bpp3PUJKiihrWvozyHQyt2HZMklXezKfPcBS3ZekQ9bg287Hiysi/oySU7zD0wgD9FoYnr0p3tO+rO9h1LexgALvH8l/91+XnGukNaHNlKDatV0K6jp5XnkE6eveDSJrSenzYePKFzF/IkSWv3prucTz2VrcaB3gqtV9lZaB47naM3NyVLku5pXPWy43Go4P2AyyHQNINCEwBghLeHuyTp9LncQs83qFpBDap6a/7G5D/pp5xOZxe/YPQq7653HrlVNptNB9Kz9K/Nh5X827li9wNrcGPu3Igy/TLQL7/8ooEDB/5hm+zsbGVmZrp8srOzr9EIAQCFsUn62+21tevoKf3vt7OFtunSuJqSfzurPamnL9tP48CKal+/slbvTivW/X/NOKdZ6w7phTX7ND3+oNxsNk3r0URVvMsXqx8AV6dMF5onTpzQokWL/rBNTEyMfH19XT7T/hlzjUYIACjM0DvrqI6/l6bGHSj0vIe7TR0b+mvtnssXkHUqe+kf4Q31QeIRbTucWaz770nNUvy+4zp0/Kx2Hj2ll77ar4xzF9S1SUCx+oF12Ax+rKxUp84///zzPzx/8ODBP+1jwoQJio6OdjnmcLdf1bgAAFduyB211baOn8Z/vlvHs84X2uaO+v6yl3NT3H+PF3q+lp+nXuzWSKt3p2nJtqNXPabcPIcOpp9RdV/++wBcS6VaaPbs2VM2m00Oh+OybWx/smbCbrfLbnf9i+Mca78BoFQMuaO2QutV1oTP9yj1VM5l23VpXFWb/3dSmYX8hV27sqde6tZY8f9N13tbfi2RcbnZpDr+Xkr8JaNE+sMNyOrRoyGlOnVevXp1ffrpp8rLyyv0s3Xr1tIcHsqwM1lZ2rN7t/bs3i1J+vXwYe3ZvVtHjxwp5ZEB1jX0zjrqdHMVTYs7qDPnc+XnVU5+XuXk4e76X/DqPnb9pXolrSlk2rxOZS+93L2xth3O0LLtKc4+fDxdc5F6VbxUr4qXPMu7y9ezvOpV8VItP0/n+X6ta6hVTR8FVrKrQdUKGn1XfQVUsmtNMdd6Arg6pZpoBgcHKzExUT169Cj0/J+lnbCuXbt2avCAx50/vzr14rrc+3s8oBdefqW0hgVYWsRfLq5/fOX+xi7HZ3xz0GWK/J7GVZV+Okfbfim47vKO+pXl51Ved91SVXfd8v9bF6WeytagxdudP7/ep5nzzzdX81anm6u4tKlod9fwDnVVuUJ5nc7O1f60LI1Zvlu/nOStcxSOX0Fphs1RipXct99+q6ysLN17772Fns/KytKPP/6ojh2Lt18iU+fAjavP21tKewgADFnxZNtSu/cPB8wtqwhp4Gus77KuVBPN9u3b/+F5b2/vYheZAAAAxcU2mmawYTsAALA86kwzyvQ+mgAAALh+kWgCAAAQaRpBogkAAAAjKDQBAIDl2Qz+r7g2bNig7t27q0aNGrLZbFq+fLnLeYfDoYkTJ6p69ery8vJSWFiY9u3b59LmxIkTevTRR+Xj4yM/Pz8NGjRIp0+fdmmzfft2tW/fXp6enqpVq5amTp1aYCwff/yxGjduLE9PTzVv3lxffvllsZ6FQhMAAKAMycrKUosWLTR37txCz0+dOlWzZ8/WggUL9MMPP8jb21vh4eE6d+7/94l99NFHtWvXLq1du1YrVqzQhg0b9MQTTzjPZ2ZmqkuXLqpTp44SExM1bdo0TZo0SW+++aazzaZNm/Twww9r0KBB2rZtm3r27KmePXtq586dRX6WUt1H0xT20QRuXOyjCdy4SnMfzcSfC/4CgZISXNfniq+12WxatmyZevbsKelimlmjRg2NHj1aTz/9tCQpIyNDgYGBio2NVb9+/bR79241bdpUW7ZsUZs2bSRJq1ev1n333afDhw+rRo0amj9/vp599lmlpKTIw8NDkjR+/HgtX75ce/bskST17dtXWVlZWrFihXM87dq1U8uWLbVgwYIijZ9EEwAAwKDs7GxlZma6fLKzs6+or0OHDiklJUVhYWHOY76+vgoJCVFCQoIkKSEhQX5+fs4iU5LCwsLk5uamH374wdmmQ4cOziJTksLDw7V371799ttvzjaX3ie/Tf59ioJCEwAAWJ7N4CcmJka+vr4un5iYmCsaZ0pKiiQpMDDQ5XhgYKDzXEpKigICAlzOlytXTv7+/i5tCuvj0ntcrk3++aJgeyMAAACD2xtNmDBB0dHRLsfsdru5G5YhFJoAAAAG2e32Eissg4KCJEmpqamqXr2683hqaqpatmzpbHPs2DGX6y5cuKATJ044rw8KClJqaqpLm/yf/6xN/vmiYOocAABYXlna3uiP1KtXT0FBQYqLi3Mey8zM1A8//KDQ0FBJUmhoqE6ePKnExERnm/j4eOXl5SkkJMTZZsOGDTp//ryzzdq1a9WoUSNVrlzZ2ebS++S3yb9PUVBoAgAAlCGnT59WUlKSkpKSJF18ASgpKUnJycmy2WwaOXKkXnzxRX3++efasWOHHn/8cdWoUcP5ZnqTJk1077336m9/+5s2b96s7777TsOGDVO/fv1Uo0YNSdIjjzwiDw8PDRo0SLt27dKSJUs0a9Yslyn+ESNGaPXq1Zo+fbr27NmjSZMm6ccff9SwYcOK/CxMnQMAAMuzlaFfQfnjjz+qc+fOzp/zi7/IyEjFxsZq7NixysrK0hNPPKGTJ0/qzjvv1OrVq+Xp6em85v3339ewYcN09913y83NTb1799bs2bOd5319ffXVV18pKipKwcHBqlq1qiZOnOiy1+btt9+uxYsX67nnntMzzzyjm2++WcuXL1ezZs2K/CzsowngusI+msCNqzT30UxKPmWs75a1Kxnru6wj0QQAAJZXhgLNGwprNAEAAGAEiSYAAACRphEUmgAAwPJKehsiXMTUOQAAAIwg0QQAAJZXlrY3upGQaAIAAMAIEk0AAGB5BJpmkGgCAADACBJNAAAAIk0jSDQBAABgBIkmAACwPPbRNINEEwAAAEaQaAIAAMtjH00zKDQBAIDlUWeawdQ5AAAAjCDRBAAAINI0gkQTAAAARpBoAgAAy2N7IzNINAEAAGAEiSYAALA8tjcyg0QTAAAARpBoAgAAyyPQNINCEwAAgErTCKbOAQAAYASJJgAAsDy2NzKDRBMAAABGkGgCAADLY3sjM0g0AQAAYASJJgAAsDwCTTNINAEAAGAEiSYAAACRphEUmgAAwPLY3sgMps4BAABgBIkmAACwPLY3MoNEEwAAAEaQaAIAAMsj0DSDRBMAAABGkGgCAAAQaRpBogkAAAAjSDQBAIDlsY+mGRSaAADA8tjeyAymzgEAAGAEiSYAALA8Ak0zSDQBAABgBIkmAACwPNZomkGiCQAAACNINAEAAFilaQSJJgAAAIwg0QQAAJbHGk0zKDQBAIDlUWeawdQ5AAAAjCDRBAAAlsfUuRkkmgAAADCCRBMAAFiejVWaRpBoAgAAwAgSTQAAAAJNI0g0AQAAYASJJgAAsDwCTTMoNAEAgOWxvZEZTJ0DAADACBJNAABgeWxvZAaJJgAAAIwg0QQAACDQNIJEEwAAAEaQaAIAAMsj0DSDRBMAAABGkGgCAADLYx9NMyg0AQCA5bG9kRlMnQMAAMAIEk0AAGB5TJ2bQaIJAAAAIyg0AQAAYASFJgAAAIxgjSYAALA81miaQaIJAAAAI0g0AQCA5bGPphkUmgAAwPKYOjeDqXMAAAAYQaIJAAAsj0DTDBJNAAAAGEGiCQAAQKRpBIkmAAAAjCDRBAAAlsf2RmaQaAIAAMAIEk0AAGB57KNpBokmAAAAjCDRBAAAlkegaQaFJgAAAJWmEUydAwAAwAgSTQAAYHlsb2QGiSYAAACMINEEAACWx/ZGZpBoAgAAwAibw+FwlPYggCuVnZ2tmJgYTZgwQXa7vbSHA6AE8e83cP2j0MR1LTMzU76+vsrIyJCPj09pDwdACeLfb+D6x9Q5AAAAjKDQBAAAgBEUmgAAADCCQhPXNbvdrueff54XBYAbEP9+A9c/XgYCAACAESSaAAAAMIJCEwAAAEZQaAIAAMAICk0AAAAYQaGJ69rcuXNVt25deXp6KiQkRJs3by7tIQG4Shs2bFD37t1Vo0YN2Ww2LV++vLSHBOAKUWjiurVkyRJFR0fr+eef19atW9WiRQuFh4fr2LFjpT00AFchKytLLVq00Ny5c0t7KACuEtsb4boVEhKitm3bas6cOZKkvLw81apVS8OHD9f48eNLeXQASoLNZtOyZcvUs2fP0h4KgCtAoonrUk5OjhITExUWFuY85ubmprCwMCUkJJTiyAAAQD4KTVyX0tPTlZubq8DAQJfjgYGBSklJKaVRAQCAS1FoAgAAwAgKTVyXqlatKnd3d6WmprocT01NVVBQUCmNCgAAXIpCE9clDw8PBQcHKy4uznksLy9PcXFxCg0NLcWRAQCAfOVKewDAlYqOjlZkZKTatGmj2267TTNnzlRWVpYGDBhQ2kMDcBVOnz6t/fv3O38+dOiQkpKS5O/vr9q1a5fiyAAUF9sb4bo2Z84cTZs2TSkpKWrZsqVmz56tkJCQ0h4WgKuwbt06de7cucDxyMhIxcbGXvsBAbhiFJoAAAAwgjWaAAAAMIJCEwAAAEZQaAIAAMAICk0AAAAYQaEJAAAAIyg0AQAAYASFJgAAAIyg0AQAAIARFJoAyqz+/furZ8+ezp87deqkkSNHXvNxrFu3TjabTSdPnrzm9waA6xmFJoBi69+/v2w2m2w2mzw8PNSwYUNNmTJFFy5cMHrfTz/9VC+88EKR2lIcAkDpK1faAwBwfbr33nv17rvvKjs7W19++aWioqJUvnx5TZgwwaVdTk6OPDw8SuSe/v7+JdIPAODaINEEcEXsdruCgoJUp04dDR06VGFhYfr888+d090vvfSSatSooUaNGkmSfvnlFz300EPy8/OTv7+/evTooZ9//tnZX25urqKjo+Xn56cqVapo7NixcjgcLvf8/dR5dna2xo0bp1q1aslut6thw4Z6++239fPPP6tz586SpMqVK8tms6l///6SpLy8PMXExKhevXry8vJSixYttHTpUpf7fPnll7rlllvk5eWlzp07u4wTAFB0FJoASoSXl5dycnIkSXFxcdq7d6/Wrl2rFStW6Pz58woPD1elSpX07bff6rvvvlPFihV17733Oq+ZPn26YmNj9c4772jjxo06ceKEli1b9of3fPzxx/XBBx9o9uzZ2r17t9544w1VrFhRtWrV0ieffCJJ2rt3r44ePapZs2ZJkmJiYvSvf/1LCxYs0K5duzRq1Cj99a9/1fr16yVdLIh79eql7t27KykpSYMHD9b48eNNfW0AcENj6hzAVXE4HIqLi9OaNWs0fPhwpaWlydvbWwsXLnROmf/73/9WXl6eFi5cKJvNJkl699135efnp3Xr1qlLly6aOXOmJkyYoF69ekmSFixYoDVr1lz2vv/973/10Ucfae3atQoLC5Mk1a9f33k+f5o9ICBAfn5+ki4moC+//LK+/vprhYaGOq/ZuHGj3njjDXXs2FHz589XgwYNNH36dElSo0aNtGPHDv3zn/8swW8NAKyBQhPAFVmxYoUqVqyo8+fPKy8vT4888ogmTZqkqKgoNW/e3GVd5k8//aT9+/erUqVKLn2cO3dOBw4cUEZGho4ePaqQkBDnuXLlyqlNmzYFps/zJSUlyd3dXR07dizymPfv368zZ87onnvucTmek5OjVq1aSZJ2797tMg5JzqIUAFA8FJoArkjnzp01f/58eXh4qEaNGipX7v//OvH29nZpe/r0aQUHB+v9998v0E+1atWu6P5eXl7Fvub06dOSpJUrV+qmm25yOWe3269oHACAy6PQBHBFvL291bBhwyK1bd26tZYsWaKAgAD5+PgU2qZ69er64Ycf1KFDB0nShQsXlJiYqNatWxfavnnz5srLy9P69eudU+eXyk9Uc3NznceaNm0qu92u5OTkyyahTZo00eeff+5y7Pvvv//zhwQAFMDLQACMe/TRR1W1alX16NFD3377rQ4dOqR169bpqaee0uHDhyVJI0aM0CuvvKLly5drz549+vvf//6He2DWrVtXkZGRGjhwoJYvX+7s86OPPpIk1alTRzabTStWrFBaWppOnz6tSpUq6emnn9aoUaO0aNEiHThwQFu3btXrr7+uRYsWSZKGDBmiffv2acyYMdq7d68WL16s2NhY018RANyQKDQBGFehQgVt2LBBtWvXVq9evdSkSRMNGjRI586dcyaco0eP1mOPPabIyEiFhoaqUqVKeuCBB/6w3/nz56tPnz76+9//rsaNG+tvf/ubsrKyJEk33XSTJk+erPHjxyswMFDDhg2TJL3wwgv6xz/+oZiYGDVp0kT33nuvVq5cqXr16kmSateurU8++UTLly9XixYttGDBAr388ssGvx0AuHHZHJdbaQ8AAABcBRJNAAAAGEGhCQAAACMoNAEAAGAEhSYAAACMoNAEAACAERSaAAAAMIJCEwAAAEZQaAIAAMAICk0AAAAYQaEJAAAAIyg0AQAAYMT/AT33qzeTgTzMAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"# Save the model to output directory\noutput_dir = \"/kaggle/working/ai_vs_human_model\"\nos.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the final model\nif isinstance(best_model, torch.nn.DataParallel):\n    model_to_save = best_model.module\nelse:\n    model_to_save = best_model\n\nmodel_to_save.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)\nprint(f\"\\nFinal model saved to {output_dir}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:51:09.680230Z","iopub.execute_input":"2025-05-02T15:51:09.680456Z","iopub.status.idle":"2025-05-02T15:51:11.416978Z","shell.execute_reply.started":"2025-05-02T15:51:09.680437Z","shell.execute_reply":"2025-05-02T15:51:11.416139Z"}},"outputs":[{"name":"stdout","text":"\nFinal model saved to /kaggle/working/ai_vs_human_model\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Save a test prediction function\nwith open(f\"{output_dir}/predict.py\", \"w\") as f:\n    f.write(\"\"\"\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ndef predict(text, model_path=\"./\"):\n    # Load model and tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n    \n    # Set device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    \n    # Tokenize input\n    inputs = tokenizer(\n        text,\n        max_length=256,\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt'\n    )\n    \n    # Move inputs to device\n    input_ids = inputs['input_ids'].to(device)\n    attention_mask = inputs['attention_mask'].to(device)\n    \n    # Make prediction\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n    \n    # Get probabilities and predicted class\n    probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n    predicted_class = torch.argmax(probabilities, dim=1).item()\n    \n    # Return prediction and probability\n    return {\n        \"prediction\": \"AI Generated\" if predicted_class == 1 else \"Human Written\",\n        \"class\": predicted_class,\n        \"probability\": probabilities[0][predicted_class].item()\n    }\n\n# Example usage\nif __name__ == \"__main__\":\n    test_text = \"This is a sample text to classify.\"\n    result = predict(test_text)\n    print(f\"Prediction: {result['prediction']}\")\n    print(f\"Class: {result['class']}\")\n    print(f\"Probability: {result['probability']:.4f}\")\n\"\"\")\n\nprint(\"\\nAlso saved a prediction script at {}/predict.py\".format(output_dir))\n\n# Try the model on a few examples\nprint(\"\\nTesting the model on a few examples:\")\nexample_texts = [\n    \"The Electoral College has been kept for centuries as a way to balance power.\",\n    \"Artificial intelligence systems have been designed to generate text that mimics human writing patterns.\",\n    \n]\n\nbest_model.eval()\nfor text in example_texts:\n    encoding = tokenizer(\n        text,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt'\n    )\n    \n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n    \n    with torch.no_grad():\n        outputs = best_model(input_ids=input_ids, attention_mask=attention_mask)\n    \n    probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n    predicted_class = torch.argmax(probabilities, dim=1).item()\n    \n    print(\"\\nText:\", text)\n    print(\"Prediction:\", \"AI Generated\" if predicted_class == 1 else \"Human Written\")\n    print(f\"Probability: {probabilities[0][predicted_class].item():.4f}\")\n\n# Print final summary\nprint(\"\\n\" + \"=\"*50)\nprint(\"Training Complete!\")\nprint(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T16:05:08.427519Z","iopub.execute_input":"2025-05-02T16:05:08.428125Z","iopub.status.idle":"2025-05-02T16:05:08.486314Z","shell.execute_reply.started":"2025-05-02T16:05:08.428107Z","shell.execute_reply":"2025-05-02T16:05:08.485717Z"}},"outputs":[{"name":"stdout","text":"\nAlso saved a prediction script at /kaggle/working/ai_vs_human_model/predict.py\n\nTesting the model on a few examples:\n\nText: The Electoral College has been kept for centuries as a way to balance power.\nPrediction: AI Generated\nProbability: 1.0000\n\nText: Artificial intelligence systems have been designed to generate text that mimics human writing patterns.\nPrediction: AI Generated\nProbability: 1.0000\n\n==================================================\nTraining Complete!\nBest Validation Accuracy: 0.9989\nTest Accuracy: 0.9985\n==================================================\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}